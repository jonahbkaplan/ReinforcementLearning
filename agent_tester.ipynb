{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af8071c5552a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "import highway_env\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import record_videos, show_videos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make('highway-fast-v0', render_mode='rgb_array',max_episode_steps=-1)\n",
    "env.unwrapped.action_type.ACTIONS_ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e5ae200c8779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.Agent import Agent\n",
    "from algorithms.RDQN import RDQN\n",
    "\n",
    "# agent = TestAgent(env)\n",
    "\n",
    "\n",
    "agent: Agent = RDQN(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1158d9b7c114177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: 15.142783461303813\n",
      "Episode 444\n",
      "Total Reward: 22.83296858535594\n",
      "Episode 445\n",
      "Total Reward: 12.046445497630883\n",
      "Episode 446\n",
      "Total Reward: 16.17834849209367\n",
      "Episode 447\n",
      "Total Reward: 12.61198221545475\n",
      "Episode 448\n",
      "Total Reward: 23.2202211687638\n",
      "Episode 449\n",
      "Total Reward: 8.346445616731947\n",
      "Episode 450\n",
      "Total Reward: 15.411681546976133\n",
      "Episode 451\n",
      "Total Reward: 7.01182383995658\n",
      "Episode 452\n",
      "Total Reward: 4.533333333333334\n",
      "Episode 453\n",
      "Total Reward: 8.978576808400764\n",
      "Episode 454\n",
      "Total Reward: 11.545486990242162\n",
      "Episode 455\n",
      "Total Reward: 18.109156376229244\n",
      "Episode 456\n",
      "Total Reward: 20.742799893499402\n",
      "Episode 457\n",
      "Total Reward: 22.649282746763166\n",
      "Episode 458\n",
      "Total Reward: 12.078820323580057\n",
      "Episode 459\n",
      "Total Reward: 7.933559839982886\n",
      "Episode 460\n",
      "Total Reward: 3.4467961636381084\n",
      "Episode 461\n",
      "Total Reward: 22.150728130571324\n",
      "Episode 462\n",
      "Total Reward: 7.199377276124429\n",
      "Episode 463\n",
      "Total Reward: 22.865420555677854\n",
      "Episode 464\n",
      "Total Reward: 1.1182336398733663\n",
      "Episode 465\n",
      "Total Reward: 24.811689906590928\n",
      "Episode 466\n",
      "Total Reward: 17.71086627305147\n",
      "Episode 467\n",
      "Total Reward: 18.377531893771305\n",
      "Episode 468\n",
      "Total Reward: 19.500350666007776\n",
      "Episode 469\n",
      "Total Reward: 16.133333227878015\n",
      "Episode 470\n",
      "Total Reward: 4.879307652733428\n",
      "Episode 471\n",
      "Total Reward: 22.953554502369677\n",
      "Episode 472\n",
      "Total Reward: 28.311063315194083\n",
      "Episode 473\n",
      "Total Reward: 23.644727212412782\n",
      "Episode 474\n",
      "Total Reward: 3.8957739152082262\n",
      "Episode 475\n",
      "Total Reward: 7.5459746738266045\n",
      "Episode 476\n",
      "Total Reward: 22.984708523903826\n",
      "Episode 477\n",
      "Total Reward: 21.109278156162105\n",
      "Episode 478\n",
      "Total Reward: 12.745501458676063\n",
      "Episode 479\n",
      "Total Reward: 2.8131583425367057\n",
      "Episode 480\n",
      "Total Reward: 3.852649669979071\n",
      "Episode 481\n"
     ]
    }
   ],
   "source": [
    "NUM_EPISODES = 1000\n",
    "total_rewards = []\n",
    "env.reset()\n",
    "# env = record_videos(env)\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "  print(f\"Episode {episode}\")\n",
    "  total_reward = 0\n",
    "  done = truncated = False\n",
    "\n",
    "  obs, info = env.reset()\n",
    "  while not (done or truncated):\n",
    "    action = agent.predict(obs.flatten())\n",
    "\n",
    "    next_obs, reward, done, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    agent.learn(obs.flatten(),action,reward,(done,next_obs.flatten()))\n",
    "\n",
    "    obs=next_obs\n",
    "    env.render()\n",
    "  total_rewards.append(total_reward)\n",
    "  print(f\"Total Reward: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9dba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "window = 20\n",
    "smoothed = np.convolve(total_rewards, np.ones(window)/window, mode='valid')\n",
    "\n",
    "plt.plot(total_rewards, alpha=0.3)\n",
    "plt.plot(smoothed)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"DQN Training (Smoothed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b75390",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = 10\n",
    "total_rewards = []\n",
    "env = gymnasium.make('highway-v0', render_mode='rgb_array',config={\"duration\":80,\"vehicles_count\": 150})\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "  print(f\"Episode {episode}\")\n",
    "  done = truncated = False\n",
    "\n",
    "  obs, info = env.reset()\n",
    "  while not (done or truncated):\n",
    "    action = agent.predict(obs.flatten())\n",
    "\n",
    "    next_obs, reward, done, truncated, info = env.step(action)\n",
    "    print(info)\n",
    "    obs=next_obs\n",
    "    env.render()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
